{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# make sure CUDA is installed\n","!nvcc --version\n","\n","# make sure you have a GPU runtime (if this fails go to runtime -> change runtime type)\n","!nvidia-smi\n","\n","# Install some magic to run and save .cpp programs\n","!curl -o ./cpu_runner.py https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/cpu_runner.py\n","%load_ext cpu_runner\n","\n","# Install some magic to run and save .cu C++ CUDA programs\n","!curl -o ./gpu_runner.py https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/gpu_runner.py\n","%load_ext gpu_runner\n","\n","# to learn about how to do more fancy things with CUDA using this API see:\n","# https://nvcc4jupyter.readthedocs.io/en/latest/index.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3LSs39Q6dPmL","executionInfo":{"status":"ok","timestamp":1733870127397,"user_tz":300,"elapsed":330,"user":{"displayName":"Mahdi Mohammed Ali-Raihan","userId":"18443592315154275798"}},"outputId":"b237ab87-e692-4b76-c31e-6f7b1e2b06ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n","Tue Dec 10 22:35:26 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  4689  100  4689    0     0  12466      0 --:--:-- --:--:-- --:--:-- 12470\n","The cpu_runner extension is already loaded. To reload it, use:\n","  %reload_ext cpu_runner\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  3082  100  3082    0     0   8194      0 --:--:-- --:--:-- --:--:--  8175\n","The gpu_runner extension is already loaded. To reload it, use:\n","  %reload_ext gpu_runner\n"]}]},{"cell_type":"code","source":["!curl -o ./matrix_lib.o https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/matrix_lib.o\n","!curl -o ./matrix_lib.h https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/matrix_lib.h"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Imyp-A9xeFDf","executionInfo":{"status":"ok","timestamp":1733870130847,"user_tz":300,"elapsed":1193,"user":{"displayName":"Mahdi Mohammed Ali-Raihan","userId":"18443592315154275798"}},"outputId":"baf90fec-42e1-41aa-e880-423604b0813b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  2336  100  2336    0     0   4831      0 --:--:-- --:--:-- --:--:--  4826\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   234  100   234    0     0    643      0 --:--:-- --:--:-- --:--:--   644\n"]}]},{"cell_type":"markdown","source":["This is multithreaded numpy code for solving a linear system of equation. It runs faster than true serial code for solving a linear system of equation.\n","It uses multiprocessing library to support using threads across multiple processors (so parallel processing + multithreading; do note that Google Colab supports 2 vCPU processors)"],"metadata":{"id":"VFpL3V2iPVW6"}},{"cell_type":"code","source":["import numpy as np\n","from concurrent.futures import ThreadPoolExecutor\n","import time\n","import os\n","from multiprocessing import Pool\n","\n","def row_multiply(args):\n","    row, matrix2 = args\n","    return np.dot(row, matrix2)\n","\n","def multithreaded_matrix_multiply(matrix1, matrix2):\n","    with Pool() as pool:\n","        results = pool.map(row_multiply, [(row, matrix2) for row in matrix1])\n","    return np.array(results)\n","\n","\n","def invert_matrix(matrix):\n","    \"\"\"Invert a single matrix.\"\"\"\n","    return np.linalg.inv(matrix)\n","\n","def multithreaded_matrix_inversion(matrices):\n","    \"\"\"\n","    Perform matrix inversion on a list of matrices using multithreading.\n","    \"\"\"\n","    with ThreadPoolExecutor(max_workers=os.cpu_count()*2) as executor:\n","        results = list(executor.map(invert_matrix, matrices))\n","\n","    return results\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    # Random matrices for demonstration\n","    matrix_A = np.random.randint(1, 11, size=(100, 100))\n","    matrix_B = np.random.randint(1, 11, size=(100, 1))\n","\n","    # print(\"Matrix A:\")\n","    # print(matrix_A)\n","    # print()\n","\n","    # print(\"Matrix B:\")\n","    # print(matrix_B)\n","    # print()\n","\n","    # Multithreaded matrix inversion\n","    matrices_to_invert = [matrix_A]  # Can add more matrices to this list\n","\n","    start = time.perf_counter()\n","    inverted_matrices = multithreaded_matrix_inversion(matrices_to_invert)\n","\n","    # print(\"Inverted Matrix A:\")\n","    # print(inverted_matrices[0])\n","\n","    matrix_X = multithreaded_matrix_multiply(inverted_matrices[0], matrix_B)\n","\n","    end = time.perf_counter()\n","    elapsed = end - start\n","    print(f\"Elapsed time: {elapsed:.6f} seconds\")\n","\n","    # print(\"Matrix X:\")\n","    # print(matrix_X)\n","    # print(\"Matrix X:\")\n","    # print(matrix_X_serial)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0fatyGFNqBqV","executionInfo":{"status":"ok","timestamp":1733766350156,"user_tz":480,"elapsed":311,"user":{"displayName":"Moises Mata","userId":"00012638527855602112"}},"outputId":"71ade04e-fec9-4dd2-ef07-162dceec4187"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Elapsed time: 0.059147 seconds\n"]}]},{"cell_type":"markdown","source":["This is true serial way of solving a system of linear equations by hand (no huge optimizations or innate multithreading that numpy does for you). It runs slower than the multithreaded numpy code"],"metadata":{"id":"MBR4X8HrPJvJ"}},{"cell_type":"code","source":["import time\n","import numpy as np\n","\n","def matrix_inverse(matrix):\n","    # Get the number of rows/columns\n","    n = len(matrix)\n","\n","    # Create augmented matrix (matrix | identity)\n","    augmented_matrix = [row[:] + [1 if i == j else 0 for j in range(n)] for i, row in enumerate(matrix)]\n","\n","    # Perform Gaussian elimination\n","    for i in range(n):\n","        # Make the diagonal element 1\n","        if augmented_matrix[i][i] == 0:\n","            raise ValueError(\"Matrix is singular and cannot be inverted.\")\n","\n","        # Scale the row so that the pivot element is 1\n","        scale = augmented_matrix[i][i]\n","        for j in range(2 * n):\n","            augmented_matrix[i][j] /= scale\n","\n","        # Eliminate the column below the pivot\n","        for j in range(i + 1, n):\n","            factor = augmented_matrix[j][i]\n","            for k in range(2 * n):\n","                augmented_matrix[j][k] -= factor * augmented_matrix[i][k]\n","\n","    # Back substitution\n","    for i in range(n - 1, -1, -1):\n","        for j in range(i - 1, -1, -1):\n","            factor = augmented_matrix[j][i]\n","            for k in range(2 * n):\n","                augmented_matrix[j][k] -= factor * augmented_matrix[i][k]\n","\n","    # Extract the inverse matrix from the augmented matrix\n","    inverse_matrix = [row[n:] for row in augmented_matrix]\n","    return inverse_matrix\n","\n","def matrix_multiply(A, B):\n","    # Check if multiplication is possible (columns of A == rows of B)\n","    if len(A[0]) != len(B):\n","        raise ValueError(\"Matrix dimensions are incompatible for multiplication.\")\n","\n","    # Initialize result matrix with zeros\n","    result = [[0] * len(B[0]) for _ in range(len(A))]\n","\n","    for i in range(len(A)):  # Iterate over rows of A\n","        for j in range(len(B[0])):  # Iterate over columns of B\n","            for k in range(len(B)):  # Iterate over rows of B\n","                result[i][j] += A[i][k] * B[k][j]\n","    return result\n","\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    # Random matrices for demonstration\n","    matrix_A = np.random.randint(1, 11, size=(100, 100)).tolist()  # Convert numpy array to list of lists\n","    matrix_B = np.random.randint(1, 11, size=(100, 1)).tolist()    # Convert numpy array to list of lists\n","\n","    # Invert matrix A\n","    start = time.perf_counter()\n","    inverted_matrix_A = matrix_inverse(matrix_A)  # Pass matrix_A instead of matrices_to_invert\n","\n","    # Multiply inverted matrix A by matrix B\n","    matrix_X_serial = matrix_multiply(inverted_matrix_A, matrix_B)\n","\n","    end = time.perf_counter()\n","    elapsed = end - start\n","    print(f\"Elapsed time: {elapsed:.6f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUekPYLCMtpT","executionInfo":{"status":"ok","timestamp":1733766466275,"user_tz":480,"elapsed":719,"user":{"displayName":"Moises Mata","userId":"00012638527855602112"}},"outputId":"9469b4a4-17d5-44f4-bc0e-12a189be076b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Elapsed time: 0.370257 seconds\n"]}]},{"cell_type":"markdown","source":["This is the serial way of solving a system of linear equations using numpy, but because numpy is automatically multithreaded (since it uses OpenBLAS or MKL, which the environment variable for these on the OS may prefer more than 1 thread) this technically is multithreaded..."],"metadata":{"id":"AVuxpng1EwDK"}},{"cell_type":"code","source":["import numpy as np\n","from concurrent.futures import ThreadPoolExecutor\n","import time\n","\n","def matrix_multiply_serial(matrix1, matrix2):\n","    \"\"\"\n","    Perform matrix multiplication in a single-threaded/serial manner.\n","    \"\"\"\n","    if matrix1.shape[1] != matrix2.shape[0]:\n","        raise ValueError(\"Matrix dimensions are incompatible for multiplication.\")\n","\n","    result = np.zeros((matrix1.shape[0], matrix2.shape[1]))\n","    for i in range(matrix1.shape[0]):  # Iterate over rows of matrix1\n","        for j in range(matrix2.shape[1]):  # Iterate over columns of matrix2\n","            result[i, j] = np.dot(matrix1[i, :], matrix2[:, j])  # Compute dot product\n","    return result\n","\n","def invert_matrix_serial(matrix):\n","    \"\"\"Invert a single matrix.\"\"\"\n","    return np.linalg.inv(matrix)\n","\n","def invert_matrices_serial(matrices):\n","    \"\"\"\n","    Invert a list of matrices in a single-threaded/serial manner.\n","    \"\"\"\n","    results = [invert_matrix_serial(matrix) for matrix in matrices]\n","    return results\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    # Random matrices for demonstration\n","    matrix_A = np.random.randint(1, 11, size=(5000, 5000))\n","    matrix_B = np.random.randint(1, 11, size=(5000, 1))\n","\n","    # print(\"Matrix A:\")\n","    # print(matrix_A)\n","    # print()\n","\n","    # print(\"Matrix B:\")\n","    # print(matrix_B)\n","    # print()\n","\n","    # Single-threaded matrix inversion\n","    matrices_to_invert = [matrix_A]  # Can add more matrices to this list\n","\n","    start = time.perf_counter()\n","    inverted_matrices = invert_matrices_serial(matrices_to_invert)\n","    matrix_X_serial = matrix_multiply_serial(inverted_matrices[0], matrix_B)\n","\n","    end = time.perf_counter()\n","    elapsed = end - start\n","    print(f\"Elapsed time: {elapsed:.6f} seconds\")\n","\n","    # print(\"Matrix X:\")\n","    # print(matrix_X_serial)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCX67mBd_lmX","executionInfo":{"status":"ok","timestamp":1733764839982,"user_tz":480,"elapsed":16120,"user":{"displayName":"Moises Mata","userId":"00012638527855602112"}},"outputId":"49e3b0dd-8a04-4cc7-8e4f-b40268a8ae04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Elapsed time: 15.528819 seconds\n"]}]},{"cell_type":"code","source":["import os\n","\n","print(os.cpu_count()) # Only 2 cores, means 2 threads are being used in multithreading..."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-zmR0GvoEUtv","executionInfo":{"status":"ok","timestamp":1733764839982,"user_tz":480,"elapsed":10,"user":{"displayName":"Moises Mata","userId":"00012638527855602112"}},"outputId":"635a7045-a20f-4d35-c4b6-f660d03ffb51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}]},{"cell_type":"code","source":["%%gpurun -n my_kernel.cu\n","#include <cstdio>\n","#include <cuda_runtime.h>\n","\n","// This function runs on the GPU\n","__global__ void helloWorldKernel() {\n","    printf(\"Hello World!\\n\");\n","}\n","\n","// This function runs on the CPU\n","__host__\n","int main() {\n","    // Launch the kernel on the GPU\n","    helloWorldKernel<<<1, 1>>>();\n","\n","    // Wait for the kernel to finish executing\n","    cudaDeviceSynchronize();\n","\n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FSHg0g6ldvBh","executionInfo":{"status":"ok","timestamp":1733865964239,"user_tz":300,"elapsed":2419,"user":{"displayName":"Mahdi Mohammed Ali-Raihan","userId":"18443592315154275798"}},"outputId":"8c499dcb-f6c5-4baf-9c9f-ed8a2f2945b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Hello World!\n","\n"]}]},{"cell_type":"code","source":["%%gpurun -n cuda_matmul.cu -o matrix_lib.o\n","#include <iostream>\n","#include <cmath>\n","#include <cuda_runtime.h>\n","#include \"matrix_lib.h\"\n","#define THREAD_BLOCK_SIZE 6  // Number of threads per block in each dimension\n","\n","// Paste your Problem 3 solution for comparison\n","void matrixMultiplyCPU_float(float* A, float* B, float* C, int M, int N, int P) {\n","  for (int i = 0; i <  M; i++){\n","    for (int j = 0; j < P; j++){\n","        float sum = 0;\n","        for (int k = 0; k < N; k++) {\n","            sum += A[k + i * N] * B[j + k * P];\n","        }\n","        C[j + i * P] = sum;\n","    }\n","  }\n","}\n","\n","/*\n","// CUDA kernel to multiply two matrices A[M][N] * B[N][P] = C[M][P]\n","// Specify what work to complete via threadIdx, blockIdx, blockDim\n","// Compute one element of the resulting matrix\n","__global__ void matrixMultiplyCUDA(float* A, float* B, float* C, int M, int N, int P) {\n","\n","    for (int j = threadIdx.y; j < M; j += blockDim.y) {\n","      for (int i = threadIdx.x; i < P; i += blockDim.x){\n","          // every thread is adding to this sum value because they share this\n","          // sum variable (because they have shared memory)\n","          float sum = 0;\n","          for (int k = 0; k < N; k++) {\n","            sum += A[j * N + k] * B[k * P + i];\n","          }\n","          C[j * P + i] = sum;\n","      }\n","      __syncthreads();\n","    }\n","}\n","*/\n","\n","__global__ void matrixMultiplyCUDA(float* A, float* B, float* C, int M, int N, int P) {\n","    int tx = threadIdx.x;  // Local thread ID in x\n","    int ty = threadIdx.y;  // Local thread ID in y\n","\n","    int blockRow = blockIdx.y * THREAD_BLOCK_SIZE;\n","    int blockCol = blockIdx.x * THREAD_BLOCK_SIZE;\n","\n","    // Each thread computes a tile of the output matrix\n","    for (int row = blockRow + ty; row < blockRow + THREAD_BLOCK_SIZE && row < N; row += THREAD_BLOCK_SIZE) {\n","        for (int col = blockCol + tx; col < blockCol + THREAD_BLOCK_SIZE && col < N; col += THREAD_BLOCK_SIZE) {\n","            float value = 0.0f;\n","\n","            // Perform the multiplication for this element\n","            for (int k = 0; k < N; ++k) {\n","                value += A[row * N + k] * B[k * N + col];\n","            }\n","\n","            // Write the result to the output matrix, with bounds check\n","            if (row < N && col < N) {\n","                C[row * N + col] = value;\n","            }\n","        }\n","    }\n","}\n","\n","\n","// GPU Device Function\n","// - actually solve the matrix inverse!\n","__device__\n","void matrix_inverse_inner(float *s_input, float *s_output, float *s_temp, const int matrix_dim){\n","  // Set up the matrix with identity next to it\n","  for (int i = 0, j = 0; i < matrix_dim; i++) {\n","      s_temp[i * matrix_dim + j] = 1;\n","      j++;\n","  }\n","  // all threads needs to wait on s_temp being filled appropriately\n","  __syncthreads();\n","\n","  // Do Guassian elimination walking down the matrix (assuming no leading 0s).\n","  // We therefore use the columns in order as the pivot column for each pivot we need to rescale\n","  // that row so that the pivot value is 1 THEN for all other row values we need to add a multiple\n","  // of the NEW pivot row value such that we transorm the other row pivot column value to 0.\n","  // See https://www.mathsisfun.com/algebra/matrix-inverse-row-operations-gauss-jordan.html\n","  //\n","  // Note if you would prefer to use another method that is fine but/and this is the method\n","  // we have a solution for and are prepared to help you with!\n","\n","  // consider threads equaling matrix dims\n","  for (unsigned pivRC = 0, j = 0; pivRC < matrix_dim; pivRC++){\n","      float leading_rc = s_input[pivRC * matrix_dim + j];\n","\n","      // first divide in the pivot row with the leading_rc\n","      s_temp[pivRC * matrix_dim + threadIdx.x] /= leading_rc;\n","      s_input[pivRC * matrix_dim + threadIdx.x] /= leading_rc;\n","\n","      // wait for all threads to perform division on the pivot row\n","      __syncthreads();\n","\n","      // each thread will take control of a row in a column and perform subtraction on\n","      // that row.\n","      // outer for loop is used in the event that there's less threads used than there\n","      // are with matrix_dim\n","      for (unsigned i = threadIdx.x; i < matrix_dim; i += blockDim.x) {\n","        unsigned mult_by_ind = i * matrix_dim + j;\n","        unsigned row_start = i * matrix_dim;\n","        // don't perform subtraction on pivot row\n","        if (mult_by_ind != (pivRC * matrix_dim + j)) {\n","            float mult_by = s_input[mult_by_ind];\n","            for (int col = 0; col < matrix_dim; col += 1) {\n","                // subtract the identity matrix appropriately\n","                s_temp[row_start + col] -=  mult_by * s_temp[pivRC * matrix_dim + col];\n","                // printf(\"%f\\n\", s_temp[row_start + col]);\n","                // subtract the input matrix appropriately\n","                s_input[row_start + col] -= mult_by * s_input[pivRC * matrix_dim + col];\n","            }\n","        }\n","      }\n","      // wait for all threads to perform subtraction on all other rows besides\n","      // pivot row to ready up for next iteration\n","      __syncthreads();\n","\n","\n","      j++;\n","  }\n","  // make sure all threads are done with their work in the for loop\n","  // before writing output\n","  __syncthreads();\n","\n","  // Make sure to write the result to the output\n","  for (unsigned i = threadIdx.x; i < matrix_dim * matrix_dim; i += blockDim.x) {\n","      s_output[i] = s_temp[i];\n","  }\n","  __syncthreads();\n","}\n","\n","\n","// GPU kernel\n","// - Set up shared memory, run the _inner, clean up shared memory\n","__global__\n","void matrix_inverse_kernel(float *d_input, float *d_output, const int matrix_dim){\n","  // get shared pointers\n","  extern __shared__ float s_dynShared[];\n","  float *s_input = (float *) (s_dynShared);\n","  float *s_output = (float *) (s_dynShared + (matrix_dim * matrix_dim) * sizeof(float));\n","  float *s_temp = (float *) (s_dynShared + 2 * (matrix_dim * matrix_dim) * sizeof(float));\n","\n","  // printf(\"%f\\n\", s_input[0]);\n","  // copy the d_input data into shared memory\n","  // do this a bit faster through threads\n","  for (int i = threadIdx.x; i < matrix_dim * matrix_dim; i += blockDim.x) {\n","      s_input[i] = d_input[i];\n","      s_temp[i] = 0;\n","  }\n","\n","  // wait for all threads to finish populating the arrays\n","  __syncthreads();\n","\n","  // printf(\"%f\\n\", s_input[0]);\n","  // run the code\n","\n","  matrix_inverse_inner(s_input, s_output, s_temp, matrix_dim);\n","  // wait for this matrix_inverse_inner function to finish\n","  // actually no need to sync here because the function does it for us\n","  // __syncthreads();\n","\n","  // copy the memory back out to d_output\n","\n","  for (int i = threadIdx.x; i < matrix_dim * matrix_dim; i += blockDim.x) {\n","    d_output[i] = s_output[i];\n","  }\n","  // make sure the output to give to host is all synced up.\n","  __syncthreads();\n","}\n","\n","\n","// Host function\n","// - set up GPU memory, run the kernel, clean up GPU memory\n","__host__\n","void matrix_inverse(float *h_input, float *h_output, const int matrix_dim){\n","\n","  // transfer memory to the device\n","  // float* h_in = (float *) malloc(matrix_dim * matrix_dim * sizeof(float));\n","  // float* h_out = (float *) malloc(matrix_dim * matrix_dim * sizeof(float));\n","  float *d_input, *d_output;\n","  cudaMalloc(&d_input, matrix_dim * matrix_dim * sizeof(float));\n","  cudaMalloc(&d_output, matrix_dim * matrix_dim * sizeof(float));\n","  cudaMemcpy(d_input, h_input, matrix_dim * matrix_dim * sizeof(float), cudaMemcpyHostToDevice);\n","  cudaMemcpy(d_output, h_output, matrix_dim * matrix_dim * sizeof(float), cudaMemcpyHostToDevice);\n","\n","  // printf(\"%f\\n\", h_input[0]);\n","  // run the kernel\n","  matrix_inverse_kernel<<<1, matrix_dim, 3 * (matrix_dim * matrix_dim * sizeof(float) * sizeof(float *))>>>(d_input, d_output, matrix_dim);\n","  cudaDeviceSynchronize();\n","\n","  // transfer data back to the host and clean up\n","  cudaMemcpy(h_output, d_output, matrix_dim * matrix_dim * sizeof(float), cudaMemcpyDeviceToHost);\n","  cudaFree(d_input);\n","  cudaFree(d_output);\n","}\n","\n","\n","// Compare matrices represented as flat arrays with single loop\n","// Allow for some floating-point error (GPU and CPU may differ slightly)\n","bool compareMatrices(const float* A, const float* B, int total_elements) {\n","    float epsilon = 0.001f; // Tolerance for floating-point comparison\n","    int precision_issues = 0;\n","\n","    // Note: not traversing in row-major order\n","    for (int i = 0; i < total_elements; ++i) {\n","        float diff = fabs(A[i] - B[i]);\n","        if (diff > epsilon) {\n","            printf(\"Matrices differ at element %d: A[%d] = %f, B[%d] = %f\\n\", i, i, A[i], i, B[i]);\n","            return false;\n","        } else if (diff > epsilon / 10 && diff <= epsilon) {\n","            precision_issues++;\n","        }\n","    }\n","\n","    if (precision_issues > 0) {\n","        printf(\"Warning: %d elements had values close to the precision threshold.\\n\", precision_issues);\n","    }\n","\n","    return true;\n","}\n","\n","int main() {\n","    const int rows_A = 5, cols_A = 5;\n","    const int rows_B = 5, cols_B = 5;\n","    const int rows_C = rows_A, cols_C = cols_B;\n","\n","    const int matrix_dim = 5;\n","    const int matrix_dim_sq = matrix_dim*matrix_dim;\n","\n","    float *h_input = (float *) malloc(matrix_dim_sq*sizeof(float));\n","\n","    // Fill matrix A and B (similar to as you did in the CPU version)\n","    float A_arr[rows_A * cols_A] = {\n","        2, 1, 3, 0, -1,\n","        0, 1, 2, 4, 1,\n","        1, 0, 1, 2, 3,\n","        4, -2, 1, 3, 0,\n","        3, 2, -1, 1, 1\n","    };\n","\n","    for (int i = 0; i < rows_A * cols_A; i++) {\n","        h_input[i] = A_arr[i];\n","    }\n","    float *h_output = (float *)malloc(matrix_dim_sq*sizeof(float));\n","\n","    // Allocate memory for matrices A, B, C\n","    // * C_gpu will be for copying and comparison purposes\n","    float* h_A = (float *) malloc(rows_A * cols_A * sizeof(float)); // TODO\n","    float* h_B = (float *) malloc(rows_B * cols_B * sizeof(float)); // TODO\n","    float* h_C_cpu = (float *) malloc(rows_C * cols_C * sizeof(float)); // TODO\n","    float* h_C_gpu = (float *) malloc(rows_C * cols_C * sizeof(float));\n","\n","\n","    if (h_A == nullptr) {\n","        fprintf(stderr, \"Memory allocation for h_A failed\\n\");\n","        return 1;\n","    }\n","\n","    if (h_B == nullptr) {\n","        fprintf(stderr, \"Memory allocation for h_B failed\\n\");\n","        return 1;\n","    }\n","\n","    if (h_C_cpu == nullptr) {\n","        fprintf(stderr, \"Memory allocation for h_C_cpu failed\\n\");\n","        return 1;\n","    }\n","\n","    if (h_C_gpu == nullptr) {\n","        fprintf(stderr, \"Memory allocation for h_C_gpu failed\\n\");\n","        return 1;\n","    }\n","\n","    matrix_inverse(h_input,h_output,matrix_dim);\n","\n","    print_float_matrix(h_output, matrix_dim, matrix_dim);\n","    for (int i = 0; i < rows_A * cols_A; i++) {\n","        h_A[i] = h_output[i];\n","    }\n","\n","    float B_arr[rows_B * cols_B] = {\n","      20.0, 21.0, 22.0, 23.0,\n","      24.0, 25.0, 26.0, 27.0,\n","      28.0, 29.0, 30.0, 31.0,\n","      32.0, 33.0, 34.0, 35.0,\n","      36.0, 37.0, 38.0, 39.0,\n","      40.0, 41.0, 42.0, 43.0,\n","      44.0\n","    };\n","\n","    for (int i = 0; i < rows_B * cols_B; i++) {\n","        h_B[i] = B_arr[i];\n","    }\n","\n","    float C_arr[cols_C * rows_C] = {0.0};\n","\n","    for (int i = 0; i < rows_C * cols_C; i++) {\n","        h_C_cpu[i] = C_arr[i];\n","        h_C_gpu[i] = C_arr[i];\n","    }\n","\n","    // Perform matrix multiplication on CPU (C++)\n","    matrixMultiplyCPU_float(h_A, h_B, h_C_cpu, rows_A, cols_A, cols_B);\n","    printf(\"CPU Matrix Multiply:\\n\");\n","    print_float_matrix(h_C_cpu, rows_C, cols_C);\n","\n","    // Perform matrix multiplication on GPU (CUDA)\n","    // create d_ device pointers, allocate GPU memory, and fill the memory\n","    float *d_A, *d_B, *d_C;\n","    cudaMalloc(&d_A, rows_A * cols_A * sizeof(float));\n","    cudaMalloc(&d_B, rows_B * cols_B * sizeof(float));\n","    cudaMalloc(&d_C, rows_C * cols_C * sizeof(float));\n","    cudaMemcpy(d_A, h_A, rows_A * cols_A * sizeof(float), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_B, h_B, rows_B * cols_B * sizeof(float), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_C, h_C_gpu, rows_C * cols_C * sizeof(float), cudaMemcpyHostToDevice);\n","\n","    // dim3 grid(1, 1);\n","    // dim3 block(2, 2);\n","    dim3 block(THREAD_BLOCK_SIZE, THREAD_BLOCK_SIZE);\n","    dim3 grid((cols_A + THREAD_BLOCK_SIZE - 1) / THREAD_BLOCK_SIZE, (cols_A + THREAD_BLOCK_SIZE - 1) / THREAD_BLOCK_SIZE);\n","\n","    // Define grid/block dimensions, then launch the kernel\n","    matrixMultiplyCUDA<<<grid, block>>>(d_A, d_B, d_C, rows_A, cols_A, cols_B);\n","    cudaDeviceSynchronize();\n","\n","    // Copy result back to host (h_C_gpu) for comparison\n","    cudaMemcpy(h_C_gpu, d_C, rows_C * cols_C * sizeof(float), cudaMemcpyDeviceToHost);\n","\n","    printf(\"\\nGPU Matrix Multiply:\\n\");\n","    print_float_matrix(h_C_gpu, rows_C, cols_B);\n","\n","    // Compare the CPU and GPU results\n","    if (compareMatrices(h_C_cpu, h_C_gpu, rows_C*cols_C)) {\n","        printf(\"\\nMatrices match!\\n\");\n","    } else {\n","        printf(\"\\nMatrices do NOT match.\\n\");\n","    }\n","\n","    // Free memory\n","    cudaFree(d_A);\n","    cudaFree(d_B);\n","    cudaFree(d_C);\n","    free(h_A);\n","    free(h_B);\n","    free(h_C_cpu);\n","    free(h_C_gpu);\n","    free(h_input);\n","\n","    return 0;\n","}"],"metadata":{"id":"W7EtxowOf_1R","executionInfo":{"status":"ok","timestamp":1733870582148,"user_tz":300,"elapsed":2306,"user":{"displayName":"Mahdi Mohammed Ali-Raihan","userId":"18443592315154275798"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4a9fb25f-38e5-4f59-ddb5-a9e84f917e16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","   0.08   -0.12    0.03    0.11    0.13 \n","   0.08    0.13   -0.09   -0.18    0.22 \n","   0.25   -0.00    0.14   -0.04   -0.16 \n","  -0.14    0.25   -0.14    0.08    0.03 \n","  -0.02   -0.13    0.37   -0.08   -0.01 \n","CPU Matrix Multiply:\n","   8.15    8.37    8.58    8.80    9.02 \n","   4.44    4.60    4.75    4.90    5.06 \n","   1.30    1.48    1.67    1.85    2.04 \n","   3.33    3.42    3.50    3.58    3.67 \n","   4.63    4.77    4.92    5.06    5.20 \n","\n","GPU Matrix Multiply:\n","   8.15    8.37    8.58    8.80    9.02 \n","   4.44    4.60    4.75    4.90    5.06 \n","   1.30    1.48    1.67    1.85    2.04 \n","   3.33    3.42    3.50    3.58    3.67 \n","   4.63    4.77    4.92    5.06    5.20 \n","\n","Matrices match!\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ByYmomSijnN0"},"execution_count":null,"outputs":[]}]}